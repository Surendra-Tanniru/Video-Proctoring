{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Mouth open\n",
      "None\n",
      "None\n",
      "Mouth open\n",
      "None\n",
      "None\n",
      "Mouth open\n",
      "None\n",
      "None\n",
      "Mouth open\n",
      "None\n",
      "None\n",
      "Mouth open\n",
      "None\n",
      "None\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "None\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "3\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "Mouth open\n",
      "3\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "3\n",
      "3\n",
      "Looking up\n",
      "Mouth open\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "Mouth open\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Mouth open\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "1\n",
      "1\n",
      "Looking left\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "## Below code is to detect Face, eye, mouth, nose and detect eye pupil and its movement\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "#start web cam\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#read the harr_face_detect_classifier.xml\n",
    "face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Surendra\\\\Facial Recognition\\\\data\\\\haarcascades\\\\haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Surendra\\\\Facial Recognition\\\\data\\\\haarcascades\\\\haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Surendra\\\\Facial Recognition\\\\data\\\\haarcascades\\\\haarcascade_smile.xml')\n",
    "nose_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Surendra\\\\Facial Recognition\\\\data\\\\haarcascades\\\\haarcascade_mcs_nose.xml')\n",
    "\n",
    "def print_eye_pos(img, left, right):\n",
    "    if left == right and left != 0:\n",
    "        text = ''\n",
    "        if left == 1:\n",
    "            print('Looking left')\n",
    "            text = 'Looking left'\n",
    "        elif left == 2:\n",
    "            print('Looking right')\n",
    "            text = 'Looking right'\n",
    "        elif left == 3:\n",
    "            print('Looking up')\n",
    "            text = 'Looking up'\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(img, text, (30, 30), font,  \n",
    "                   1, (0, 255, 255), 2, cv2.LINE_AA) \n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords\n",
    "\n",
    "def eye_on_mask(mask, side, shape):\n",
    "    points = [shape[i] for i in side]\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    mask = cv2.fillConvexPoly(mask, points, 255)\n",
    "    l = points[0][0]\n",
    "    t = (points[1][1]+points[2][1])//2\n",
    "    r = points[3][0]\n",
    "    b = (points[4][1]+points[5][1])//2\n",
    "    return mask, [l, t, r, b]\n",
    "\n",
    "def find_eyeball_position(end_points, cx, cy):\n",
    "    x_ratio = (end_points[0] - cx)/(cx - end_points[2])\n",
    "    y_ratio = (cy - end_points[1])/(end_points[3] - cy)\n",
    "    if x_ratio > 3:\n",
    "        return 1\n",
    "    elif x_ratio < 0.33:\n",
    "        return 2\n",
    "    elif y_ratio < 0.33:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def contouring(thresh, mid, img, end_points, right=False):       \n",
    "    cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    try:\n",
    "        cnt = max(cnts, key = cv2.contourArea)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        if right:\n",
    "            cx += mid\n",
    "        cv2.circle(img, (cx, cy), 4, (0, 0, 255), 2)\n",
    "        pos = find_eyeball_position(end_points, cx, cy)\n",
    "        return pos\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def process_thresh(thresh):\n",
    "    thresh = cv2.erode(thresh, None, iterations=2) \n",
    "    thresh = cv2.dilate(thresh, None, iterations=4) \n",
    "    thresh = cv2.medianBlur(thresh, 3) \n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    return thresh\n",
    "\n",
    "\n",
    "left = [36, 37, 38, 39, 40, 41]\n",
    "right = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "kernel = np.ones((9, 9), np.uint8)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:\\\\Users\\\\Surendra\\\\OneDrive\\\\Desktop\\\\shape_predictor_68_face_landmarks (1).dat')\n",
    "    \n",
    "outer_points = [[49, 59], [50, 58], [51, 57], [52, 56], [53, 55]]\n",
    "d_outer = [0]*5\n",
    "inner_points = [[61, 67], [62, 66], [63, 65]]\n",
    "d_inner = [0]*3\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "\n",
    "while True:\n",
    "    #read video frame by frame\n",
    "    ret, frame= capture.read()\n",
    "    \n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_cords = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=1)\n",
    "\n",
    "    #draw rectange over faces\n",
    "    for x, y, w, h in face_cords:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255,0), thickness=2)\n",
    "        roi_gray = gray_frame[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        #draw rectange over eyes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.1, minNeighbors=5)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "        #draw rectange over mouth\n",
    "        smile = smile_cascade.detectMultiScale(roi_gray,scaleFactor=1.1, minNeighbors=15)\n",
    "        for (xx, yy, ww, hh) in smile:\n",
    "            cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 255, 0), 2)\n",
    "        #draw rectange over nose\n",
    "#        nose = nose_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "#        for (nx, ny, nw, nh) in nose:\n",
    "#            cv2.rectangle(roi_color, (nx,ny), (nx+nw,ny+nh), (0, 0, 255), 3)\n",
    "    \n",
    "    rects = detector(gray_frame, 1)\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray_frame, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "        mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        mask, end_points_left = eye_on_mask(mask, left, shape)\n",
    "        mask, end_points_right = eye_on_mask(mask, right, shape)\n",
    "        mask = cv2.dilate(mask, kernel, 5)\n",
    "        eyes = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        mask = (eyes == [0, 0, 0]).all(axis=2)\n",
    "        eyes[mask] = [255, 255, 255]\n",
    "        mid = int((shape[42][0] + shape[39][0]) // 2)\n",
    "        eyes_gray = cv2.cvtColor(eyes, cv2.COLOR_BGR2GRAY)\n",
    "         # increase the threshold in threshold window to detect eye pupi\n",
    "        threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "        _, thresh = cv2.threshold(eyes_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "        thresh = process_thresh(thresh)\n",
    "#        print(thresh)\n",
    "        eyeball_pos_left = contouring(thresh[:, 0:mid], mid, frame, end_points_left)\n",
    "        print(eyeball_pos_left)\n",
    "        eyeball_pos_right = contouring(thresh[:, mid:], mid, frame, end_points_right, True)\n",
    "        print(eyeball_pos_right)\n",
    "        print_eye_pos(frame, eyeball_pos_left, eyeball_pos_right)\n",
    "#    cv2.imshow(\"image\", thresh)    \n",
    "    cnt_outer = 0\n",
    "    cnt_inner = 0\n",
    "    for i, (p1, p2) in enumerate(outer_points):\n",
    "        if d_outer[i] + 3 < shape[p2][1] - shape[p1][1]:\n",
    "            cnt_outer += 1 \n",
    "    for i, (p1, p2) in enumerate(inner_points):\n",
    "        if d_inner[i] + 2 <  shape[p2][1] - shape[p1][1]:\n",
    "            cnt_inner += 1\n",
    "    if cnt_outer > 3 and cnt_inner > 2:\n",
    "        print('Mouth open')\n",
    "        cv2.putText(frame, 'Mouth open', (30, 30), font,\n",
    "                1, (0, 255, 255), 2)\n",
    "\n",
    "    # increase the threshold in threshold window to detect eye pupil\n",
    "#    cv2.imshow(\"image\", thresh)\n",
    "        #show face detect Video\n",
    "    cv2.imshow(\"Detect face live Video\", frame)\n",
    "\n",
    "\n",
    "#    if cv.waitKey(20) ==ord(\"e\"):              # press e to exit\n",
    "    if cv2.waitKey(20) > 0 :                    # press any key to exit   \n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
